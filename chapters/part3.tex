% !TeX root = ../main.tex
\chapter{Extrema \& other applications}
\bookletstart

\lettrine{I}{n} the previous chapter we introduced various notions of differentials for higher dimensional functions (scalar fields, vector fields, paths, etc.).
In this chapter we now explore various applications of these notions and work with some of the implementations, rather than just the objects.
Firstly we will consider certain partial differential equations which we now have the tools to solve.
Then the majority of the chapter is devoted to searching for extrema (minima / maxima) in various different scenarios.
This extends what we already know for functions in \(\bR\) and we will find that in higher dimensions many more possibilities and subtleties exist.

\section{Higher partial derivatives}
Just like with derivatives, we can take higher order partial derivatives.
For convenience when we want to write \(\frac{\partial}{\partial y}\frac{\partial}{\partial x}f(x,y) \), i.e., differentiate first with respect to \(x\) and then with respect to \(y\), we write instead \(\frac{\partial^2 f}{\partial y \partial x}(x,y) \).
The analogous notation is used for higher derivatives and any other choice of coordinates.

We first consider the question of when
\[
    \frac{\partial^2 f}{\partial y \partial x}(x,y)
    \overset{\text{\large\color{blue}?}}{=}
    \frac{\partial^2 f}{\partial x \partial y}(x,y).
\]

\begin{example*}[partial derivative problem]
    Let \(f:\bR^2 \to \bR\) be defined as \(f(0,0)=0\) and, for \((x,y)\neq (0,0)\),
    \[
        f(x,y) := \frac{x y(x^2 - y^2)}{x^2 + y^2}.
    \]
    We calculate that \(\frac{\partial^2 f}{\partial y \partial x} (0,0) = -1\) but
    \(\frac{\partial^2 f}{\partial x \partial y}(0,0) = 1\).
\end{example*}

\begin{theorem}%
    \label{thm:equal-double-partial}
    Let \(f:S\to\bR\) be a scalar field such that the partial derivatives \(\frac{\partial f}{\partial x }\), \(\frac{\partial f}{\partial y}\) and \(\frac{\partial^2 f}{\partial y \partial x}, \frac{\partial^2 f}{\partial x \partial y} \) exist on an open set \(S\subset \bR^2\) containing \(\xx = (a,b)\).
    Further assume that \(\frac{\partial^2 f}{\partial y \partial x}, \frac{\partial^2 f}{\partial x \partial y} \) is continuous on \(S\).
    Then, for $\xx = (a,b) \in S$,
    \[
        \frac{\partial^2 f}{\partial x \partial y} (\xx)=\frac{\partial^2 f}{\partial y \partial x} (\xx).
    \]
\end{theorem}
\begin{proof}
 Let us write $D_1 = \frac{\partial}{\partial x}, D_2 = \frac{\partial}{\partial y}$.
 By the mean value theorem applied to $G(x) = f(x,b+k) - f(x,b), G'(x) = D_1 f(x,b+k) - D_1 f(x,b)$,
 \begin{align*}
  &(f(a+h,b+k) - f(a+h,b)) - (f(a,b+k) - f(a,b)) \\
  &= h G'(a+\theta_1 h) \\
  &= h (D_1 f'(a+\theta_1 h, b+k) - D_1 f'(a+\theta_1 h, b)) \\
  &= hk D_2 D_1f(a+\theta_1 h, b+\varphi_1 k),
 \end{align*}
 where $0\le \theta, \varphi \le 1$, and we applied the mean value theorem to $D_1 f(a+\theta_1 h, y) = H(y)$.
 Similarly,
 $(f(a+h,b+k) - f(a+h,b)) - (f(a,b+k) - f(a,b)) = hk D_1 D_2f(a+\theta_2 h, b+\varphi_2 k)$,
 hence
 \[
  D_1 D_2 f(a+\theta_2 h, b+\varphi_2 k) = D_2 D_1f(a+\theta_2 h, b+\varphi_2 k).
 \]
 As $h,k\to 0$, this shows $D_1 D_2 f(a,b) = D_2 D_1 f(a,b)$.
\end{proof}


\section{Partial differential equations}
A partial differential equation is an equation about a scalar field or a vector field
involving its partial derivatives.
\begin{example}
 Some (linear) partial differential equations.
 \begin{itemize}
  \item $\frac{\partial f}{\partial t}(x,t) = k\frac{\partial^2 f}{\partial x^2}(x,y)$, where $k$ is a constant (heat equation)
  \item $\frac{\partial^2 f}{\partial x^2}(x,y) + \frac{\partial^2 f}{\partial y^2}(x,y) = 0$ (Laplace's equation)
  \item $\frac{\partial^2 f}{\partial x^2}(x,t) - \frac1{c^2}\frac{\partial^2 f}{\partial t^2}(x,t) = 0$, where $c$ is a constant (wave equation)
 \end{itemize}
 Maxwell's equations, Navier-Stokes equations, Einstein's equations...
\end{example}
In general, PDE's have many solutions, and need to specify a boundary condition (or an initial condition):

Consider $\frac{\partial f}{\partial x}(x,y) = 0$. For any function $g(y)$, $f(x,y) = g(y)$ is a solution,
and it holds that $f(0,y) = g(y)$. In general, such a condition is called a boundary condition.


There are a huge number of different types of partial differential equations (PDEs) and here we consider just two types, \emph{first order linear PDEs} and the \emph{1D wave equation}.
We start by consider an example of the first type.

\begin{example*}
    Find all solutions of the PDE,
    \(3 \frac{\partial f}{\partial x}(x,y) + 2 \frac{\partial f}{\partial y} (x,y) = 0\).
\end{example*}

\begin{solution}
    The given PDE is equivalent to
    \(\left( \begin{smallmatrix}
            3 \\ 2
        \end{smallmatrix} \right)
    \cdot
    \nabla f(x,y) =0\).
    We can also phrase this in terms of the directional derivative, namely
    \[
        D_{\mathbf{v}}f(x,y) = 0 \quad \text{where \(\mathbf{v}=\left( \begin{smallmatrix}
                3 \\ 2
            \end{smallmatrix} \right)\)}.
    \]
    This means that if a function \(f\) is a solution to the PDE then it is constant in the direction \(\left( \begin{smallmatrix}
            3 \\ 2
        \end{smallmatrix} \right)\).
    This means that all solutions have the form \(f(x,y) = g(2x-3y)\) for some \(g:\bR \to \bR\).
\end{solution}

The same idea as used for the above example gives the following general result.

\begin{theorem}
    Let \(g:\bR\to\bR\) be differentiable, \(a,b\in \bR\), \((a,b)\neq (0,0)\).
    If \(f(x,y)= g(bx-ay)\) then
    \[
        a \frac{\partial f}{\partial x} (x,y) + b \frac{\partial f}{\partial y} (x,y) = 0.
    \]
    Conversely, every \(f\) which satisfies this equation is of the form \(g(bx-ay)\).
\end{theorem}

\begin{proof}
    First we prove \textbf{(\(\boldsymbol\Rightarrow\))}.
    If \(f(x,y)= g(bx-ay)\) then, by the chain rule,
    \[
        \partial_x f(x,y) = bg'(bx-ay),
        \quad
        \partial_y f(x,y) = -ag'(bx-ay).
    \]
    Consequently \(a\partial_x f(x,y) + b \partial_y f(x,y) = a bg'(bx-ay) - abg'(bx-ay) = 0\).
    Now we prove \textbf{(\(\boldsymbol\Leftarrow\))}.
    It's convenient to work in coordinates which correspond to the lines along which the solutions are constant.
    Let \(\left(\begin{smallmatrix}
            u\\ v
        \end{smallmatrix}\right)
    = \left(\begin{smallmatrix}
            a & b \\ b & -a
        \end{smallmatrix}\right)
    \left(\begin{smallmatrix}
            x \\ y
        \end{smallmatrix}\right)\).
    This means that
    \(\left(\begin{smallmatrix}
            x\\ y
        \end{smallmatrix}\right)
    = \frac{-1}{a^2 + b^2} \left(\begin{smallmatrix}
            -a & -b \\ -b & a
        \end{smallmatrix}\right)
    \left(\begin{smallmatrix}
            u \\ v
        \end{smallmatrix}\right)\).
    Let \(h(u,v)=f(\frac{au + bv}{a^2 + b^2}, \frac{bu-av}{a^2+b^2})\).
    We calculate that
    \[
        \partial_u h(u,v)
        = \tfrac{1}{{a^2 + b^2}}
        \left( a \partial_x f
        + b \partial_y f \right)  (au + bv, bu-av) = 0.
    \]
    Namely, \(h(u,v)\) is a function of \(v\) only and does not depend on \(u\) so we take \(g(v) = h(u,v)\) and so \(f(x,y) = g(bx-ay)\).
\end{proof}

Now we look at another type of PDE.\@
The \href{https://en.wikipedia.org/wiki/Wave_equation}{\emph{1D wave equation}} is
\[
    \frac{\partial^2 f}{\partial x^2}(x,t) = \frac1{c^2}  \frac{\partial^2 f}{\partial t^2}(x,t).
\]
Here \(x\) represents the position along string,
\(t\) is time and \(f(x,t)\) is the displacement of the string from the centre at position \(x\), at time \(t\).
The constant \(c\) is a fixed parameter depending on the string.

This partial differential equation is derived from the equation of motion \(F = m a\) where \(F\) is the tension in the string, \(a\) is the acceleration from horizontal and \(m\) is the mass of a little piece of the string.
The equation is valid for small displacement.
In this case the \emph{boundary conditions} are natural: Are the ends of the string fixed? Is only one end fixed? At time \(t=0\), is the string already moving?

\begin{theorem}
    Let \(F\) be a twice differentiable function and \(G\) a differentiable function.

    \noindent
    \textbf{1.} The function defined as
    \begin{equation}
        \label{eq:wave}
        f(x,t) = \frac{1}{2}(F(x+ct) + F(x-ct)) + \frac{1}{2c} \int_{x-ct}^{x+ct} G(s) \ ds
    \end{equation}
    satisfies \(   \frac{\partial^2 f}{\partial x^2}(x,t) = \frac1{c^2}  \frac{\partial^2 f}{\partial t^2}(x,t) \),
    \(f(x,0) = F(x)\)
    and \(\frac{\partial f}{\partial t}(x,0) = G(x)\).

    \noindent
    \textbf{2.} Conversely, if a solution of
    \[
        \frac{\partial^2 f}{\partial x^2}(x,t) = \frac1{c^2}  \frac{\partial^2 f}{\partial t^2}(x,t)
    \]
    satisfies
    \(\frac{\partial^2 f}{\partial x \partial t} = \frac{\partial^2 f}{\partial t \partial x}\),
    then it has the above form~\eqref{eq:wave}.
\end{theorem}


\begin{proof}[Proof of part 1.]
    Let \(f(x,t)\) be as defined~\eqref{eq:wave} in the statement of the theorem.
    We calculate the partial derivatives
    \[
        \begin{aligned}
            \tfrac{\partial f}{\partial x} (x,t)
             & = \tfrac{1}{2} \left(F'(x+ct) + F'(x-ct)\right)          \\
             & \quad\quad\quad
            + \tfrac{1}{2c}\left(G(x+ct) - G(x-ct)\right)               \\
            \tfrac{\partial^2 f}{\partial x^2}(x,t)
             & = \tfrac{1}{2} \left(F''(x+ct) + F''(x-ct)\right)        \\
             & \quad\quad\quad
            + \tfrac{1}{2c}\left(G'(x+ct) - G'(x-ct)\right)             \\
            \tfrac{\partial f}{\partial t} (x,t)
             & = \tfrac{1}{2} \left(cF'(x+ct) - c F'(x-ct)\right)       \\
             & \quad\quad\quad
            + \tfrac{1}{2}\left(G(x+ct) + G(x-ct)\right)                \\
            \tfrac{\partial^2 f}{\partial t^2} f(x,t)
             & = \tfrac{1}{2} \left(c^2F''(x+ct) + c^2 F''(x-ct)\right) \\
             & \quad\quad\quad
            + \tfrac{c}{2}\left(G'(x+ct) + G'(x-ct)\right).
        \end{aligned}
    \]
    From this calculation we see that  \(   \frac{\partial^2 f}{\partial x^2}(x,t) = c^2  \frac{\partial^2 f}{\partial t^2}(x,t) \).
    Additionally we have \(f(x,0) = F(x)\)
    and \(\frac{\partial f}{\partial t}(x,0) = G(x)\).
\end{proof}

\begin{proof}[Proof of part 2.]
    Suppose that \(f\) satisfies the 1D wave equation;
    Introduce \(u = x + ct\), \(v=x-ct\)
    and observe that \(x = \frac{u+v}{2}\), \(t=\frac{u-v}{2c}\).
    Define \(g(u,v) = f(   \frac{u+v}{2} , \frac{u-v}{2c} )\).
    By the chain rule
    \[
        \begin{aligned}
            \tfrac{\partial g}{\partial u}(u,v)
             & = \tfrac{1}{2} \tfrac{\partial f}{\partial x}(   \tfrac{u+v}{2} , \tfrac{u-v}{2c} )
            + \tfrac{1}{2c} \tfrac{\partial f}{\partial t}(   \tfrac{u+v}{2} , \tfrac{u-v}{2c} ),                     \\
            \tfrac{\partial^2 g}{\partial v \partial u}(u,v)
             & = \tfrac{1}{4} \tfrac{\partial^2 f}{\partial x^2}(   \tfrac{u+v}{2} , \tfrac{u-v}{2c} )
            - \tfrac{1}{4c} \tfrac{\partial^2 f}{\partial x\partial t}(   \tfrac{u+v}{2} , \tfrac{u-v}{2c} )          \\
             & \ \ +  \tfrac{1}{4c} \tfrac{\partial^2 f}{\partial x \partial t}(   \tfrac{u+v}{2} , \tfrac{u-v}{2c} )
            -  \tfrac{1}{4c^2} \tfrac{\partial^2 f}{\partial t^2}(   \tfrac{u+v}{2} , \tfrac{u-v}{2c} ) = 0.
        \end{aligned}
    \]
    Since the second derivative is zero we know that \(\tfrac{\partial g}{\partial u}\) is constant in \(v\), therefore we can write \( \tfrac{\partial g}{\partial u}(u,v) = \varphi_0(u)\).
    In turn this means we can write \(g(u,v) = \varphi_1(u) + \varphi_2(v)\).
    I.e., \(f(x,t) = \varphi_1(x+ct) + \varphi_2(x-ct)\).
    Let
    \[
        F(x) = \varphi_1(x) + \varphi_2(x), \quad
%     \]
%     This means that
%     \(F'(x) = \varphi_1'(x) + \varphi_2'(x)\)
%     and \(\frac{\partial f}{\partial t}(x,t) = c\varphi_1(x+ct) - c\varphi_2(x-ct)\).
%     Let
%     \[
        G(x) = \tfrac{\partial f}{\partial t}(x,0) = c\varphi'_1(x) - c\varphi'_2(x).
    \]
    Substituting these quantities we show that the required form~\eqref{eq:wave} is satisfied.
\qedhere
\end{proof}

\section{Extrema (minima / maxima / saddle)}

Let \(S\subset \bR^n\) be open,
\(f:S \to \bR\) be a scalar field
and \(\aa \in S\).

\begin{definition}[absolute min/max]
    If \(f(\aa)\leq f(\xx)\) (resp.\ \(f(\aa)\geq f(\xx)\)) for all \(\xx \in S\), then \(f(\aa)\) is said to be the \emph{absolute} minimum (resp.\ maximum) of \(f\).
\end{definition}

\begin{definition}[relative min/max]
    If \(f(\aa)\leq f(\xx)\) (resp.\ \(f(\aa)\geq f(\xx)\)) for all \(\xx \in B(\aa,r)\) for some \(r>0\), then \(f(\aa)\) is said to be a \emph{relative} minimum (resp.\ maximum) of \(f\).
\end{definition}

Collectively we call the these points the \emph{extrema} of the scalar field.
In the case of a scalar field defined on \(\bR^2\) we can visualize the scalar field as a 3D plot like Figure~\ref{fig:bumps}.
Here we see the extrema as the ``flat'' places.
We sometimes use \emph{global} as a synonym of \emph{absolute} and \emph{local} as a synonym of \emph{relative}.


\begin{figure}[htbp]
    \begin{center}
        \includegraphics{bumps.pdf}
        \caption{\(f(x,y) := x e^{-(x^2y^2)}  + \frac{1}{4}e^{y^\frac{3}{10}}\)}%
        \label{fig:bumps}
    \end{center}
\end{figure}

To proceed it is convenient to connect the extrema with the behaviour of the gradient of the scalar field.

\begin{theorem}%
    \label{thm:is-stationary}
    If \(f:S\to\bR\) is differentiable and has a relative minimum or maximum at \(\aa\), then \(\nabla f(\aa)=  \mathbf{0}\).
\end{theorem}

\begin{proof}
    Suppose \(f\) has a relative minimum at \(\aa\) (or consider \(-f\)).
    For any unit vector \(\vv\) let \(g(u) = f(\aa+u\vv)\).
    We know that \(g:\bR \to \bR\) has a relative minimum at \(u=0\) so \(u'(0)=0\).
    This means that the directional derivative \(D_{\vv} f(\aa) = 0\) for every \(\vv\).
    Consequently this means that \(\nabla f (\aa)= \mathbf{0}\).
\end{proof}

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=0.5\textwidth]{inflection.pdf}
        \caption{\(\nabla f(\aa) =  \mathbf{0}\) doesn't imply a minimum or maximum at \(\aa\), even in \(\bR\), as seen with the function \(f(x):=x^3\). In higher dimensions even more is possible.}%
        \label{fig:inflection}
    \end{center}
\end{figure}

Observe that here and in the subsequent text, we can always consider the case of \(f:\bR \to \bR\), i.e., the case of \(\bR^n\) where \(n=1\).
Everything still holds and reduces to the arguments and formulae previously developed for functions of one variable.


\begin{definition}[stationary point]
    If \(\nabla f(\aa)=\mathbf{0}\) then \(\aa\) is called a \emph{stationary point}.
\end{definition}


\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=0.5\textwidth]{bowl.pdf}
        \caption{If \(f(x,y)=x^2+y^2\) then \(\nabla f(x,y) = \left(\begin{smallmatrix}
                2x\\2y
            \end{smallmatrix}\right)\) and \(\nabla f(0,0) =\left(\begin{smallmatrix}
                0\\0
            \end{smallmatrix}\right) \). The point \((0,0)\) is an absolute minimum for \(f\).}
    \end{center}
\end{figure}

As we see in the example of Figure~\ref{fig:inflection}, the converse of Theorem~\ref{thm:is-stationary} fails in the sense that a stationary point might not be a minimum or a maximum.
The motivates the following.

\begin{definition}[saddle point]
    If \(\nabla f(\aa)=\mathbf{0}\) and \(\aa\) is neither a minimum nor a maximum then \(\aa\) is said to be a \emph{saddle point}.
\end{definition}

The quintessential saddle has the shape seen in Figure~\ref{fig:pringle}.
However it might be similar to Figure~\ref{fig:inflection} or more complicated using the possibilities available in higher dimension.

\begin{figure}[htbp]
    \centering
    \includegraphics{pringle.pdf}
    \caption{If \(f(x,y)=x^2-y^2\) then \(\nabla f(x,y) = \left(\begin{smallmatrix}
            2x\\-2y
        \end{smallmatrix}\right)\) and \(\nabla f(0,0) =\left(\begin{smallmatrix}
            0\\0
        \end{smallmatrix}\right) \). The point \((0,0)\) is a saddle point for \(f\).}%
    \label{fig:pringle}
\end{figure}


\section{Hessian matrix}

To proceed it is useful to develop the idea of a second order Taylor expansion in this higher dimensional setting.
In particular this will allow us to identify the local behaviour close to stationary points.
The main object for doing this is the \emph{Hessian matrix}.

\begin{definition}[Hessian matrix]
    Let \(f:\bR^2 \to\bR\) be twice differentiable and use the notation \(f(x,y)\).
    The \emph{Hessian matrix} at \(\aa\in \bR^2\) is defined as
    \[
        \mathbf{H} f (\aa)= \begin{pmatrix}
            \frac{\partial^2 f}{\partial x^2} (\aa)
             & \frac{\partial^2 f}{\partial x\,\partial y} (\aa)
            \\[1.5ex]
            \frac{\partial^2 f}{\partial y\,\partial x} (\aa)
             & \frac{\partial^2 f}{\partial y^2}(\aa)
        \end{pmatrix}.
    \]
\end{definition}

Observe that, if $f$ has continuous second partial derivatives, the Hessian matrix \(\mathbf{H} f (\aa)\) is a symmetric matrix 
because we know that \(\frac{\partial^2 f}{\partial x\,\partial y} (\aa) = \frac{\partial^2 f}{\partial y\,\partial x} (\aa)\) 
(Theorem~\ref{thm:equal-double-partial}).
The Hessian matrix is defined analogously in any dimensions as follows.
Let \(f:\bR^n \to\bR\) be twice differentiable.
The \emph{Hessian matrix} at \(\aa\in \bR^n\) is defined as
\[
    \mathbf{H} f (\aa)= \begin{pmatrix}
        \frac{\partial^2 f}{\partial x_1^2} (\aa)
         & \frac{\partial^2 f}{\partial x_1\,\partial x_2} (\aa)
         & \cdots
         & \frac{\partial^2 f}{\partial x_1\,\partial x_n}(\aa)  \\[1.5ex]
        \frac{\partial^2 f}{\partial x_2\,\partial x_1} (\aa)
         & \frac{\partial^2 f}{\partial x_2^2}(\aa)
         & \cdots
         & \frac{\partial^2 f}{\partial x_2\,\partial x_n}(\aa)  \\[1.5ex]
        \vdots
         & \vdots
         & \ddots
         & \vdots                                                \\[1.5ex]
        \frac{\partial^2 f}{\partial x_n\,\partial x_1} (\aa)
         & \frac{\partial^2 f}{\partial x_n\,\partial x_2} (\aa)
         & \cdots
         & \frac{\partial^2 f}{\partial x_n^2}(\aa)
    \end{pmatrix}.
\]

Observe that the Hessian matrix is a real symmetric matrix in any dimension.
If \(f:\bR \to \bR\) then \(\mathbf{H} f (a)\) is a \(1\times 1\) matrix and coincides with the second derivative of \(f\).
In this sense what we know about extrema in \(\bR\) is just a special case of everything we do here.

\begin{lemma*}
    If \(\vv= \left( \begin{smallmatrix}
            v_1\\ \vdots \\v_n
        \end{smallmatrix} \right)  \) then\footnote{The notation \(\vv^{\mathbf{t}}\) denotes the transpose of the vector \(\vv\).} \(\vv^{\mathbf{t}} \ \mathbf{H} f (\aa) \ \vv = \sum_{j,k=0}^{n}
    \partial_{j}\partial_{k}f(\aa)
    v_j v_k \in \bR\).
\end{lemma*}

\begin{proof}
    Multiplying the matrices we calculate that\footnote{For convenience, here and in many other places of this text, we use the notation
        \(\partial_{j}\partial_{k}f(\aa) = \frac{\partial^2 f}{\partial x_j\,\partial x_k} (\aa)\).}
    \[
        \begin{aligned}
            \vv^{\mathbf{t}} \ \mathbf{H} f (\aa) \ \vv
             & =
            \begin{pmatrix}
                v_1 & \cdots & v_n
            \end{pmatrix}
            \begin{pmatrix}
                \partial_{1}\partial_{1}f(\aa) & \cdots &
                \partial_{1}\partial_{n}f(\aa)                   \\
                \vdots                         & \ddots & \vdots \\
                \partial_{n}\partial_{1}f(\aa) & \cdots &
                \partial_{n}\partial_{n}f(\aa)
            \end{pmatrix}
            \begin{pmatrix}
                v_1 \\ \vdots \\v_n
            \end{pmatrix} \\
             & = \sum_{j,k=0}^{n}
            \partial_{j}\partial_{k}f(\aa)
            v_j v_k
        \end{aligned}
    \]
    as required.
\end{proof}


\begin{example*}
    Let \(f(x,y)=x^2-y^2\) (Figure~\ref{fig:pringle}).
    The gradient and the Hessian are respectively
    \[
        \begin{aligned}
            \nabla f(x,y)      & =\begin{pmatrix}
                \frac{\partial f}{\partial x} (x,y) \\[2pt]
                \frac{\partial f}{\partial y} (x,y)
            \end{pmatrix} =   \begin{pmatrix}
                2x \\-2y
            \end{pmatrix}, \\
            \mathbf{H} f (x,y) & = \begin{pmatrix}
                \frac{\partial^2 f}{\partial x^2} (x,y)
                 & \frac{\partial^2 f}{\partial x\,\partial y} (x,y)
                \\[2pt]
                \frac{\partial^2 f}{\partial y\,\partial x} (x,y)
                 & \frac{\partial^2 f}{\partial y^2}(x,y)
            \end{pmatrix}
            = \begin{pmatrix}
                2
                 & 0
                \\[2.2ex]
                0
                 & -2
            \end{pmatrix}.
        \end{aligned}
    \]
    The point \((0,0)\) is a stationary point since \(\nabla f(0,0) =\left(\begin{smallmatrix}
            0\\0
        \end{smallmatrix}\right) \).
    In this example \(\mathbf{H} f \) does not depend on \((x,y)\) but in general we can expect dependence and so it gives a different matrix at different points  \((x,y)\).
\end{example*}


\subsubsection*{Second order Taylor formula for scalar fields}

First let's recall the first order Taylor approximation from Theorem~\ref{thm:differential}.
If \(f\) is differentiable at \(\aa\)
then
\(  f(\xx) \approx f(\aa)  + \nabla f(\aa) \cdot (\xx-\aa)\).
If \(\aa\) is a stationary point then this only tells us that \(  f(\xx) \approx f(\aa) \) so a natural next question is to search for slightly more detailed information.

\begin{theorem}[second order Taylor]
    Let \(f\) be a scalar field twice differentiable on \(B(\aa,r)\) with continuous partial derivatives.
    Then,\footnote{We use the convention that \((\xx-\aa)\) is a vertical vector, equivalently, a \(n \times 1\) matrix.} for \(\xx\) close to \(\aa\),
    \[
        f(\xx) \approx f(\aa) + \nabla f(\aa) \cdot (\xx-\aa) + \frac{1}{2} {(\xx-\aa)}^{\mathbf{t}} \ \mathbf{H} f (\aa) \ (\xx-\aa)
    \]
    in the sense that the error is \(\littleo{\norm{(\xx-\aa)}^2}\).
\end{theorem}

\begin{proof}
    Let \(\vv = \xx-\aa\) and let \(g(u) = f(\aa + u \vv)\).
    The Taylor expansion of \(g\) tells us that
    \(g(1) = g(0) + g'(0) + \frac{1}{2} g''(c)\) for some \(c\in (0,1)\).
    Since \(g(u) = f(a_1 + uv_1, \ldots, a_n + u v_n)\), by the chain rule,
    \[
        \begin{aligned}
            g'(u)  & = \sum_{j=1}^{n} \partial_j f( a_1 + uv_1, \ldots, a_n + u v_n ) v_j
            =\nabla f( \aa + u \vv) \cdot \vv,                                                            \\
            g''(u) & = \sum_{j,k=1}^{n} \partial_j\partial_k f( a_1 + uv_1, \ldots, a_n + u v_n ) v_j v_k \\
                   & \quad \quad \quad
            =  \vv^{\mathbf{t}} \ \mathbf{H} f (\aa + u \vv) \ \vv.
        \end{aligned}
    \]
    Consequently
    \(
    f(\aa+\vv) = f(\aa) + \nabla f(\aa) \cdot \vv + \frac{1}{2} \vv^{\mathbf{t}} \ \mathbf{H} f (\aa + c\vv) \ \vv
    \).
    We define the ``error'' in the approximation as \(\epsilon(\vv) = \frac{1}{2}  \vv^{\mathbf{t}} (\mathbf{H} f (\aa + c\vv) - \mathbf{H} f (\aa)  ) \vv\)
    and estimate that
    \[
        \abs{\epsilon(\vv)} \leq \sum_{j,k=0}^{n}
        v_j v_k \left( \partial_{j}\partial_{k}f(\aa+c\vv)-\partial_{j}\partial_{k}f(\aa) \right).
    \]
    Since \(\abs{ v_j v_k} \leq \norm{\vv}^2\) we observe that \(\frac{\abs{\epsilon(\vv)} }{\norm{\vv}^2} \to 0\) as \(\norm{\vv} \to 0\) as required.
\end{proof}


\section{Classifying stationary points}
\subsubsection*{Review of linear algebra}
Let $A = (A_{jk})$ be an $n\times n$-matrix. It can be considered as a linear map $\bR^n \to \bR^n$
by $\xx \mapsto A\xx = (\sum_{j=1}^n A_{1j}x_j, \cdots, \sum_{j=1}^n A_{nj} x_j)$.
A vector $\xx$ is an eigenvector with eigenvalue $\lambda$ of $A$ if $A\xx = \lambda\xx$.

We say that $A$ is symmetric if $A_{jk} = A_{kj}$. If $A$ is symmetric, then it is diagonalizable:
there is an orthogonal matrix $B = (B_{jk}), B^{\mathbf{t}} = (B_{jk}) = B^{-1}$, such that
$BAB^{-1}$ is a diagonal matrix. Then $\ee_k$ are eigenvectors of $BAB^{-1}$.
$B^{-1}\ee_k$ are eigenvectors of $A$. Indeed, $AB^{-1}\ee_k = B^{-1}BAB^{-1}\ee_k = \lambda_k B^{-1}\ee_k$.

\subsubsection*{Classification by Hessian}

We can study the stationary point using the Hessian matrix.

In order to classify the stationary points we will take advantage of the Hessian matrix and therefore we need to first understand the follow fact about real symmetric matrices.

\begin{theorem}
    Let \(A\) be a real symmetric matrix and let
    \(Q(\vv) =  \vv^{\mathbf{t}} A  \vv  \).
    Then
    \[
        \begin{aligned}
            \text{\(Q(\vv) > 0\) for all \(\vv \neq \mathbf{0}\)}
             & \quad \Longleftrightarrow \quad
            \text{all eigenvalues of \(A\) are positive}, \\
            \text{\(Q(\vv) < 0\) for all \(\vv \neq \mathbf{0}\)}
             & \quad \Longleftrightarrow \quad
            \text{all eigenvalues of \(A\) are negative}.
        \end{aligned}
    \]
\end{theorem}

\begin{proof}
    Since \(A\) is symmetric it can be diagonalised by  matrix \(B\)  which is orthogonal (\(B^{\mathbf{t}}=B^{-1}\))
    and the diagonal matrix \(D = B A B^{\mathbf{t}}\) has the eigenvalues of \(A\) as the diagonal.
    This means that
    \(Q(\vv) = \vv^{\mathbf{t}} B^{\mathbf{t}} B A B^{\mathbf{t}} B \vv = \ww^{\mathbf{t}} D \ww \)
    where \(\ww = B \vv\).
    Consequently \(Q(\vv) =  \sum_{j} \lambda_j w_j^2\).
    Observe that, if all \(\lambda_j >0\) then \( \sum_{j} \lambda_j w_j^2  >0\).

    In order to prove the other direction in the ``if and only if'' statement, observe that \(Q(B \uu_k ) = \lambda_k\). This means that, if \(Q(\vv) > 0\) for all \(\vv \neq \mathbf{0}\) then \(\lambda_k>0\) for all \(k\).
\end{proof}

\begin{theorem}[classification of stationary points]
    Let \(f\) be a scalar field twice differentiable on \(B(\aa,r)\).
    Suppose  \(\nabla f(\aa) = \mathbf{0}\) and consider the eigenvalues of  \(\mathbf{H} f (\aa)\).
    Then
    \[
        \begin{aligned}
            \text{{All} eigenvalues are positive}
             & \quad \Longrightarrow \quad
            \text{relative minimum at \(\aa\)}, \\
            \text{{All} eigenvalues are negative}
             & \quad \Longrightarrow \quad
            \text{relative maximum at \(\aa\)}, \\
            \text{Some positive, some negative}
             & \quad \Longrightarrow \quad
            \text{\(\aa\) is a saddle point}.
        \end{aligned}
    \]
\end{theorem}

\begin{proof}
    Let \(Q(\vv) =  \vv^{\mathbf{t}} \mathbf{H} f (\aa) \vv  \),  \(\ww = B \vv\) and let \(\Lambda := \min_j \lambda_j\).
    Observe that \(\norm{\ww} =  \norm{\vv}\) and that \(Q(\vv)=  \sum_{j} \lambda_j w_j^2  \geq \Lambda \sum_{j} w_j^2 = \Lambda  \norm{\vv}^2 \).
    We have them 2\textsuperscript{nd}-order Taylor
    \[
        \begin{aligned}
            f(\aa+\vv) - f(\aa)
             & =  \frac{1}{2} \vv^{\mathbf{t}} \ \mathbf{H} f (\aa) \ \vv +  \epsilon(\vv)                \\
             & \geq  \left(\tfrac{\Lambda}{2} - \tfrac{\epsilon(\vv)}{\norm{\vv}^2} \right) \norm{\vv}^2.
        \end{aligned}
    \]
    Since \(\frac{\abs{\epsilon(\vv)}}{\norm{\vv}^2} \to 0\) as \(\norm{\vv}\to 0\), \( \frac{\abs{\epsilon(\vv)}}{\norm{\vv}^2} < \tfrac{\Lambda}{2}\) when \(\norm{\vv}\) is small.
    The argument is analogous for the second part. For final part consider \(\vv_j\) which is the eigenvector for \(\lambda_j\) and apply the argument of the first or second part.
\end{proof}

\begin{example}
 Consider $f(x,y) = x^3 + y^3 - 6xy$.
 One can find that stationary points are $(x,y) = (0,0), (2,2)$.
 The Hessian matrix is
 $\mathbb{H} f(0,0) = \begin{pmatrix} 0 & -6 \\ -6 & 0\end{pmatrix}$,
 and as its trace is $0$ while the determinant is positive, so it must have a positive and a negative eigenvalues.
 $(0,0)$ is a saddle point.
 On the other hand,
 $\mathbb{H} f(2,2) = \begin{pmatrix} 12 & -6 \\ -6 & 12\end{pmatrix}$,
 and as its trace is $24$ while the determinant is positive, so it must have two positive eigenvalues.
 $(2,2)$ is a local minimum. 
 
\end{example}


\section{Attaining extreme values}

Here we explore the extreme value theorem for continuous scalar fields.
The argument will be in two parts:
Firstly we show that continuity implies boundedness;
Secondly we show that boundedness implies that the maximum and minimum are attained.
We use the following notation for \emph{intervals} / \emph{rectangles} / \emph{cuboids} / \emph{tesseracts}, etc.
If \(\aa = (a_1,\ldots,a_n)\) and  \(\bb = (b_1,\ldots,b_n)\)
then we consider the \(n\)-dimensional closed Cartesian product
\[
    [\aa,\bb] = [a_1,b_1] \times \cdots \times [a_n,b_n].
\]
We call this set a \emph{rectangle} (independent of the dimension).
As a first step it is convenient to know that all sequences in our setting have convergent subsequences.

\begin{theorem}[Bolzano–Weierstrass]
    If \({\{\xx_{n}\}}_{n}\) is a sequence in \( [\aa,\bb]\)
    there exists a convergent subsequence \({\{\xx_{n_j}\}}_{j}\).
\end{theorem}

\begin{proof}
    In order to prove the theorem we construct the subsequence.
    Firstly we divide \( [\aa,\bb]\) into sub-rectangles of size half the original.
    We then choose a sub-rectangle which contains infinite elements of the sequence and choose the first of these elements to be part of the sub-sequence.
    We repeat this process by again dividing the sub-rectangle we chose by half and choosing the next element of the subsequence.
    We repeat to give the full subsequence.
\end{proof}

\begin{theorem}[boundedness of continuous scalar fields]
    Suppose that \(f\) is a scalar field continuous at every point in the closed rectangle \([\aa,\bb]\).
    Then \(f\) is bounded on \([\aa,\bb]\) in the sense that there exists \(C>0\) such that \(\abs{f(\xx)} \leq C\) for all \(\xx \in [\aa,\bb]\).
\end{theorem}

\begin{proof}
    Suppose the contrary: for all \(n\in\bN\) there exists \(\xx_n\in [\aa,\bb]\) such that \(\abs{f(\xx_n)}>n\).
    \href{https://en.wikipedia.org/wiki/Bolzano%E2%80%93Weierstrass_theorem}{Bolzano–Weierstrass} theorem means that there exists a subsequence \({\{\xx_{n_j}\}}_{j}\) converges to \( \xx \in [\aa,\bb]\).
    Continuity of \(f\) means that \(f(\xx_{n_j})\) converges to \(f(\xx)\). This is a contradiction and hence the theorem is proved.
\end{proof}


We can now use the above result on the boundedness in order to show that the  extreme values are actually obtained.

\begin{theorem}[extreme value theorem]
    Suppose that \(f\) is a scalar field continuous at every point in the closed rectangle \([\aa,\bb]\).
    There there exist points \( \xx, \yy \in [\aa,\bb]\) such that
    \[
        f(\xx) = \inf f
        \quad \text{and} \quad
        f(\yy)= \sup f.
    \]
\end{theorem}

\begin{proof}
    By the boundedness theorem \(\sup f\) is finite and so there exists a sequence  \({\{\xx_{n}\}}_{n}\)  such that \(f(\xx_n)\) converges to \(\sup f\).
    Bolzano–Weierstrass theorem implies that there exists a subsequence  \({\{\xx_{n_j}\}}_{j}\) which converges to \( \xx \in [\aa,\bb]\).
    By continuity \(f(\xx_n) \to f(\xx) = \sup f\).
\end{proof}




\section{Extrema with constraints (Lagrange multipliers)}

We now consider a slightly different problem to the one earlier in this chapter.
There we wished to find the extrema of a given scalar field.
Here the general problem is to minimise or maximise a given scalar field \(f(x,y)\) under the constraint \(g(x,y) = 0\).
Subsequently we will also consider the same problem but in higher dimensions.
We can visualize this problem as shown in Figure~\ref{fig:lagrange}.
For this graphic representation we draw the constraint and also various level sets of the function that we want to find the extrema of.
The graphical representation suggests to us that at the ``touching point'' the gradient vectors are parallel.
In other words, \(\nabla f = \lambda \nabla g\) for some \(\lambda \in \bR\).
The implementation of this idea is the \href{https://en.wikipedia.org/wiki/Lagrange_multiplier}{method of Lagrange multipliers}.

\begin{theorem}[Lagrange multipliers in 2D]
    Suppose that a differentiable scalar field \(f(x,y)\) has a relative minimum or maximum when it is subject to the constraint
    \[
        g(x,y) = 0.
    \]
    Then there exists a scalar \(\lambda\) such that, at the extremum point,
    \[
        \nabla f = \lambda \nabla g.
    \]
\end{theorem}

\begin{figure}[htb]
    \begin{center}
        \includegraphics{lagrange.pdf}
        \caption{Searching extrema of \(f\) under constraint \(g=0\)}%
        \label{fig:lagrange}
    \end{center}
\end{figure}

In three dimensions a similar result holds.

\begin{theorem}[Lagrange multipliers in 3D]
    Suppose that a differentiable scalar field \(f(x,y,z)\) has a relative minimum or maximum when it is subject to the constraints
    \[
        g_{1}(x,y,z) = 0,
        \quad
        g_{2}(x,y,z) = 0
    \]
    and the \(\nabla g_k\) are linearly independent.
    Then there exist scalars \(\lambda_1\), \(\lambda_2\) such that, at the extremum point,
    \[
        \nabla f = \lambda_{1} \nabla g_{1} + \lambda_{2} \nabla g_{2}.
    \]
\end{theorem}

In higher dimensions and possibly with additional constraints we have the following general theorem.

\begin{theorem*}[Lagrange multipliers]
    Suppose that a differentiable scalar field \(f(x_1,\ldots,x_n)\) has an relative extrema when it is subject to \(m\) constraints
    \[
        g_1(x_1,\ldots,x_n) = 0,
        \dots , g_m(x_1,\ldots,x_n)=0,
    \]
    where \(m<n\), and the \(\nabla g_k\) are all linearly independent.
    Then there exist \(m\) scalars \(\lambda_1,\ldots,\lambda_m\) such that, at each extremum point,
    \[
        \nabla f = \lambda_1 \nabla g_1 + \cdots + \lambda_m \nabla g_m.
    \]
\end{theorem*}

The Lagrange multiplier method is often stated and far less often proved.
Since the proof is rather involved we will follow this tradition here.
See, for example, Chapter 14 of  ``A First Course in Real Analysis''  (2012) by Protter \& Morrey for a complete proof and further discussion.

Let us consider a particular case of the method when \(n=3\) and \(m=2\).
More precisely we consider the following problem:
Find the maxima and minima of \(f(x,y,z)\) along the curve \(C\) defined as
\[
    g_1(x,y,z) = 0,
    \quad
    g_2(x,y,z) = 0
\]
where \(g_1\), \(g_2\) are differentiable functions.
In this particular case we will prove the Lagrange multiplier method.
Suppose that \(\aa\) is some point in the curve.
Let \(\aalpha(t)\) denote a path which lies in the curve \(C\) in the sense that \(\aalpha(t) \in C\) for all \(t\in (-1,1)\), \(\aalpha'(t)\neq \mathbf{0}\) and \(\aalpha(0)=\aa\).
If \(\aa\) is a local minimum for \(f\) restricted to \(C\) it means that \(f(\aalpha(t))\geq f(\aalpha(0))\) for all \(t \in (-\delta,\delta)\) for some \(\delta>0\).
In words, moving away from \(\aa\) along the curve \(C\) doesn't cause \(f(\xx)\) to decrease.
Let \(h(t) = f(\aalpha(t))\) and observe that \(h:\bR \to \bR\) so we know how to find the extrema.
In particular we know that \(h'(0)=0\).
By the chain rule \(h'(t) = \nabla f(\aalpha(t))\cdot \aalpha'(t)\) and so
\[
    \nabla f(\aa)\cdot \aalpha'(0) = 0.
\]
Since we know that \(g_1(\aalpha(t))=0\) and \(g_2(\aalpha(t))=0\), again by the chain rule,
\[
    \nabla g_1(\aa)\cdot \aalpha'(0) = 0,
    \quad
    \nabla g_2(\aa)\cdot \aalpha'(0) = 0.
\]
To proceed it is convenient to isolate the following result of linear algebra.
\begin{lemma*}
    Consider \(w, u_1,u_2 \in \bR^3\) and let \(V = \{v : u_k \cdot v = 0, k =1,2\}\).
    If \(w\cdot v =0\) for all \(v \in V\) then \(w = \lambda_1 u_1 + \lambda_2 u_2\) for some \(\lambda_1,\lambda_2 \in \bR\).
\end{lemma*}
\begin{proof}
    We can write \(w = \lambda_1 u_1 + \lambda_2 u_2 + v_0\) where \(v_0 \in V\) because \(u_1, u_2\) together with \(V\) must span \(\bR^3\).
    Since \(v_0 \in V\) and, by assumption, \(w\cdot v_0 = 0\),
    \[
        0 = w\cdot v_0
        = (\lambda_1 u_1 + \lambda_2 u_2 + v_0)\cdot v_0
        = v_0\cdot v_0
        = \norm{v_0}^2.
    \]
    This means that \(v_0 =0\) and so \(w = \lambda_1 u_1 + \lambda_2 u_2\).
\end{proof}

The above lemma also holds in any dimension with any number of vectors with the analogous proof.
Applying this lemma to the vectors \(\nabla f(\aa)\), \(\nabla g_1(\aa)\) and \(\nabla g_2(\aa)\) recovers exactly the Lagrange multiplier method in this setting.

% \subsection*{Suggested further reading}

% \begin{itemize}
%     \item Apostol, ``Calculus Volume 2'', Chapter 9
% \end{itemize}

\bookletend

