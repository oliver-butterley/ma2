% !TeX root = ../main.tex
\chapter{Worked examples}

\lettrine{T}{his} chapter contains various examples from the different parts of the course and the full calculations.
Some of the examples come from the exercises, some from past exams, some just because they are relevant to the material.

\section{Sequences \& series of functions}

\begin{task}
    Calculate the Taylor expansion of
    \(x\cos^2 x\) or \(x\sin^2 x\)
    about the point \(x=0\).
\end{task}

\begin{solution}
    We recall or calculate that \(\cos(x) = \sum_{n=0}^\infty \frac{{(-1)}^n}{(2n)!} x^{2n}\)
    and so
    \[
        \cos(2x) =
        \sum_{n=0}^\infty \frac{{(-1)}^n}{(2n)!} {(2x)}^{2n}
        = \sum_{n=0}^\infty \frac{{(-4)}^n}{(2n)!} x^{2n}.
    \]
    Additionally we know that
    \(\cos(2x) = \cos^2 x - \sin^2 x\)
    and hence
    \[
        \cos^2 x = \tfrac{1}{2} + \tfrac{1}{2} \cos(2x)
        \quad \text{and} \quad
        \sin^2 x = \tfrac{1}{2} - \tfrac{1}{2} \cos(2x).
    \]
    Combining the above we obtain
    \[
        \begin{aligned}
            x \cos^2 x
             & = \frac{x}{2} + \frac{x}{2} \cos(2x)
            =  \frac{x}{2} +  \frac{x}{2}  \sum_{n=0}^\infty \frac{{(-4)}^n}{(2n)!} x^{2n}                                                            \\
             & =  \frac{x}{2} +  \frac{x}{2} \left( 1 + \frac{-4}{2!} x^2 + \frac{{(-4)}^2}{4!} x^4 +  \frac{{(-4)}^3}{(6)!} x^{6} + \cdots   \right) \\
             & =  x  - x^3 + \frac{1}{3} x^5 -  \frac{2}{45} x^{7} + \cdots
        \end{aligned}
    \]
    On the other hand
    \[
        \begin{aligned}
            x \sin^2 x
             & = \frac{x}{2} - \frac{x}{2} \cos(2x)
            =  \frac{x}{2} -  \frac{x}{2}  \sum_{n=0}^\infty \frac{{(-4)}^n}{(2n)!} x^{2n}                                                           \\
             & =  \frac{x}{2} - \frac{x}{2} \left( 1 + \frac{-4}{2!} x^2 + \frac{{(-4)}^2}{4!} x^4 +  \frac{{(-4)}^3}{(6)!} x^{6} + \cdots   \right) \\
             & =  x^3 - \frac{1}{3} x^5 +  \frac{2}{45} x^{7} + \cdots
        \end{aligned}
    \]
    To integrate we use the fact that \(f(x) = \sum_{n=0}^{\infty}a_n x^n\) implies \(\int_0^x f(t) \ dt = \sum_{n=1}^{\infty} \frac{a_{n-1}}{n!} x^{n}\) (or simply integrate the above term-by-term) and so
    \[
        \int_0^x t \cos^2 t \ dt
        = \frac{ 1}{2}x^2  -\frac{1}{4} x^4 + \frac{1}{18} x^6 -  \frac{1}{180} x^{8} + \cdots
    \]
    and
    \[
        \int_0^x t \sin^2 t \ dt
        =  \frac{1}{4} x^4 - \frac{1}{18} x^6 +  \frac{1}{180} x^{8} + \cdots
    \]
    The Taylor expansion for \(\cos x\) converges for all \(x\) and consequently the Taylor expansions for \(\frac{1}{2}(1 + \cos (2x))\) and for  \(\frac{1}{2}(1 - \cos (2x))\) also converge for all \(x\).
\end{solution}


\begin{task}
    Consider, for \(m\in \{0,1\}\), the linear differential equation\footnote{This equation, for some constant \(m\), is called \href{https://en.wikipedia.org/wiki/Bessel_function}{Bessel's differential equation} and has various applications including: electromagnetic waves in a cylindrical waveguide; heat conduction in a cylindrical object and the modes of vibration of a circular drum.}
    \[
        x^2y'' + xy' + (x^2-m^2) y = 0.
    \]
    Using the \emph{method of undetermined coefficients} obtain a power series solution (centred at \(x=0\)) to this differential equation.
    Determine the radius of convergence \(r\) and investigate convergence at \(x = \pm r\).
\end{task}

\begin{solution}
    Substituting \(y(x) = \sum_{n=0}^{\infty} a_n x^n\), \(y'(x) = \sum_{n=1}^{\infty} n a_n x^{n-1}\) and \(y''(x) = \sum_{n=2}^{\infty} n(n-1) a_n x^{n-2}\) one obtains the equation
    \begin{multline*}
        x^2 \left(\sum_{n=2}^{\infty} n(n-1) a_n x^{n-2}\right) + x \left(\sum_{n=1}^{\infty} n a_n x^{n-1}\right) \\ + x^2 \left(\sum_{n=0}^{\infty} a_n x^n\right) - m^2 \left(\sum_{n=0}^{\infty} a_n x^n\right) = 0
    \end{multline*}
    and so
    \[
        \sum_{n=2}^{\infty} n(n-1) a_n x^{n} + \sum_{n=1}^{\infty} n a_n x^{n} + \sum_{n=0}^{\infty} a_n x^{n+2} -  \sum_{n=0}^{\infty} m^2 a_n x^n = 0.
    \]
    Shifting the index in the third sum
    \[
        \sum_{n=2}^{\infty} n(n-1) a_n x^{n} + \sum_{n=1}^{\infty} n a_n x^{n} + \sum_{n=2}^{\infty} a_{n-2} x^{n} -  \sum_{n=0}^{\infty} m^2 a_n x^n = 0.
    \]
    Consequently, separating the terms of \(x^1\) and \(x^0\),
    \[
        \sum_{n=2}^{\infty}  \left[ n(n-1)a_n + n a_n +  a_{n-2} -m^2a_n  \right] x^{n} + a_1 x - m^2 a_1 x - m^2 a_0  =0.
    \]
    Equivalently
    \[
        \sum_{n=2}^{\infty}  \left[ (n^2 - m^2)a_n +  a_{n-2}   \right] x^{n} + (1 - m^2 )a_1 x - m^2 a_0  =0.
    \]
    In the case that \(m=0\) this means that \(a_1 = 0\) and, as an immediate consequence of the given initial value, \(a_0 = 192\).
    On the other hand, in the case that \(m=1\) this means that \(a_0=0\) and, as an immediate consequence of the given initial value, \(a_1 = 192\).
    Considering the first sum in the above equation, we see that, for all \(n\geq 2\),  \( (n^2 - m^2)a_n +  a_{n-2}  = 0 \) and so
    \[
        a_n = - \frac{a_{n-2}}{n^2 - m^2}.
    \]
    The recurrence relation would allow us to determine the coefficients of the power series solution to this differential equation.
    For the first few terms we calculate that
    \[
        \begin{aligned}
            a_2 & =  - \frac{1}{2^2 - m^2}a_{0},                                          \\
            a_3 & =  - \frac{1}{3^2 - m^2}a_{1},                                          \\
            a_4 & =  - \frac{1}{4^2 - m^2}a_{2} = \frac{1}{(4^2 - m^2)(2^2 - m^2)} a_{0}, \\
            a_5 & =  - \frac{1}{5^2 - m^2}a_{3} = \frac{1}{(5^2 - m^2)(3^2 - m^2)}a_{1}.
        \end{aligned}
    \]
    Using the ratio test on the recurrence relation shows that the radius of converge of the power series solution is infinite.
\end{solution}


In the next task we will use the following notation.
For \(\alpha \in \bR\), \(n\in \bN\), let
\(  \binom{\alpha}{n}= \frac{\alpha (\alpha-1) \cdots (\alpha-n+1)}{n!}\).
This quantity is called the binomial coefficient.

\begin{task}[binomial series]
    Let \(\alpha \in \bR\).
    Show that, whenever \(\abs{x}<1\),
    \[
        {(1+x)}^\alpha = \displaystyle\sum_{n=0}^{\infty} \textstyle\binom{\alpha}{n} x^n.
    \]
\end{task}

\begin{solution}
    Using the ratio test we can confirm that the right hand side converges.
    Let \(f(x) = {(1+x)}^\alpha\).
    We calculate that \(f'(x) = \alpha {(1+x)}^{\alpha-1}\) and so \(f(x)\) is a solution to the differential equation
    \[
        y'(x) = \frac{\alpha}{x+1}y(x)
    \]
    and satisfies the initial condition \(f(0)=1\).
    To complete the proof we will show that
    \(g(x) = \sum_{n=0}^{\infty} \binom{\alpha}{n} x^n\) satisfies the same differential equation and initial condition.
    First observe that
    \( (n+1)\binom{\alpha}{n+1} = (\alpha - n)\binom{\alpha}{n} \)
    is equivalent to
    \( (n+1)\binom{\alpha}{n+1} + n \binom{\alpha}{n} = \alpha \binom{\alpha}{n}\).
    We calculate that
    \[
        g'(x)
        =  \sum_{n=1}^{\infty} n \binom{\alpha}{n} x^{n-1}
        =  \sum_{n=0}^{\infty} (n+1) \binom{\alpha}{n+1} x^n.
    \]
    Consequently
    \[
        \begin{aligned}
            (1+x)g'(x)
             & = \sum_{n=0}^{\infty} \left( (n+1)\binom{\alpha}{n+1} + n\binom{\alpha}{n}    \right)  x^n \\
             & = \alpha  \sum_{n=0}^{\infty} \binom{\alpha}{n}  x^n = \alpha g(x).
        \end{aligned}
    \]
    Additionally \(g(0) = 1\).
\end{solution}


\section{Differential calculus in higher dimension}

\begin{task}
    Let \(\mathbf{f}:\mathbb{R}^2\to\mathbb{R}^2\), \(\mathbf{g}:\mathbb{R}^3\to\mathbb{R}^2\) be defined as
    \[
        \begin{aligned}
            \mathbf{f}(x,y)   & = (e^{x+2y}, \sin(y+2x)) \\
            \mathbf{g}(u,v,w) & = (u+2v^2+3w^3,2v-u^2).
        \end{aligned}
    \]
    Let \(\mathbf{h} =\mathbf{f} \circ \mathbf{g} : \bR^3 \to \bR^2\) and calculate \(D\mathbf{h}(1,-1,1)\).
\end{task}

\begin{solution}
    We first calculate \(\mathbf{g}(1,-1,1) = (6,-3)\) and
    \[
        \begin{aligned}
            D\mathbf{f}(x,y)   & =
            \begin{pmatrix}
                e^{x+2y}     & 2 e^{x+2y} \\
                2 \cos(y+2x) & \cos(y+2x)
            \end{pmatrix}, \\
            D\mathbf{g}(u,v,w) & =
            \begin{pmatrix}
                1   & 4v & 9w^2 \\
                -2u & 2  & 0
            \end{pmatrix}.
        \end{aligned}
    \]
    Consequently
    \[
        \begin{aligned}
            D\mathbf{f}(6,-3)   & =
            \begin{pmatrix}
                1        & 2      \\
                2 \cos 9 & \cos 9
            \end{pmatrix}, \\
            D\mathbf{g}(1,-1,1) & =
            \begin{pmatrix}
                1  & -4 & 9 \\
                -2 & 2  & 0
            \end{pmatrix}.
        \end{aligned}
    \]
    By the chain rule for Jacobian matrices (Theorem~\ref{thm:jacobian-chain}),
    \( D\mathbf{h}(1,-1,1) = D\mathbf{f}(6,-3)  D\mathbf{g}(1,-1,1) \)
    and so, multiplying the matrices, we obtain
    \[
        D\mathbf{h}(1,-1,1) =
        \begin{pmatrix}
            -3 & 0        & 9        \\
            0  & -6\cos 9 & 18\cos 9
        \end{pmatrix}.
    \]
\end{solution}


\section{Extrema \& other applications}

\begin{task}
    Let \(\alpha>0\) and let, for \((x,y,z)\in \bR^3 \setminus \{(0,0,0)\}\),
    \[
        f(x,y,z) = {(x^2 + y^2 + z^2)}^{-\alpha}.
    \]
    Find \(\alpha>0\) such that
    \[
        \tfrac{\partial^2 f}{\partial x^2} + \tfrac{\partial^2 f}{\partial y^2}  +\tfrac{\partial^2 f}{\partial z^2}  =0.
    \]
\end{task}

\begin{solution}
    We calculate the partial derivatives,
    \[
        \begin{aligned}
            \tfrac{\partial f}{\partial x}(x,y)
             & = -2 \alpha x{(x^2 + y^2 + z^2)}^{-\alpha-1},           \\
            \tfrac{\partial^2 f}{\partial x^2}(x,y)
             & = 4 \alpha(\alpha+1) x^2{(x^2 + y^2 + z^2)}^{-\alpha-2} \\
             & \quad -2 \alpha {(x^2 + y^2 + z^2)}^{-\alpha-1}.
        \end{aligned}
    \]
    The partial derivatives with respect to \(y\) and \(z\) are similar, the only difference being that the first \(x^2\) in the first term is replaced by \(y^2\) or \(z^2\).
    Consequently \(\left(\tfrac{\partial^2 f}{\partial x^2} + \tfrac{\partial^2 f}{\partial y^2}  +\tfrac{\partial^2 f}{\partial z^2}\right)(x,y,x)\) is equal to
    \[
        \begin{aligned}
             & 4 \alpha(\alpha+1)( x^2 + y^2 + z^2){(x^2 + y^2 + z^2)}^{-\alpha-2} \\
             & \quad -6 \alpha {(x^2 + y^2 + z^2)}^{-\alpha-1}                     \\
             & =  4 \alpha(\alpha+1){(x^2 + y^2 + z^2)}^{-\alpha-1}                % \\
            -6 \alpha {(x^2 + y^2 + z^2)}^{-\alpha-1}                              \\
             & = (4 \alpha(\alpha+1) -6 \alpha ) {(x^2 + y^2 + z^2)}^{-\alpha-1}.
        \end{aligned}
    \]
    Since \(4 \alpha(\alpha+1) - 6 \alpha = 4\alpha^2 - 2\alpha = 2\alpha(2\alpha -1)\) we see that this is zero, for all \((x,y,z)\), when \(\alpha=0\) or when \(\alpha = \frac{1}{2}\).
    The latter is the required solution.
\end{solution}


\begin{task}
    Find the extrema of \(f(x,y) = xy\) under the constraint \(g(x,y) = x+y-1 =0\).
\end{task}

\begin{solution}
    We start by calculating that
    \[
        \nabla f(x,y) = \left(\begin{smallmatrix}
                y\\ x
            \end{smallmatrix}\right),
        \quad
        \nabla g(x,y) = \left(\begin{smallmatrix}
                1\\ 1
            \end{smallmatrix}\right).
    \]
    According to the Lagrange multiplier method there exists \(\lambda\in \bR\) such that \(\nabla f(x,y) = \lambda \nabla g(x,y)\) at any extremum point \((x,y)\).
    To proceed we must solve the system of equations (3 equations and 3 unknowns),
    \[
        \left(\begin{smallmatrix}
                y\\ x
            \end{smallmatrix}\right)
        = \lambda \left(\begin{smallmatrix}
                1\\ 1
            \end{smallmatrix}\right),
        \quad g(x,y) =0;
    \]
    That is,
    \( x = \lambda, \quad
    y = \lambda, \quad
    x+y = 1
    \).
    This has the solution \((x,y) = (\frac{1}{2},\frac{1}{2})\), \(f(\frac{1}{2},\frac{1}{2})= \frac{1}{4}\).
\end{solution}



\begin{task}
    Find the points closest to the origin on the set defined by the intersection of the two surfaces
    \[
        x^2 - xy + y^2 - z^2 = 1
        \quad \text{and} \quad
        x^2 + y^2 = 1.
    \]
\end{task}

\begin{solution}
    For convenience we let
    \[
        \begin{aligned}
            f(x,y,z)   & = x^2 + y^2 + z^2,          \\
            g_1(x,y,z) & = x^2 - xy + y^2 - z^2 - 1, \\
            g_2(x,y,z) & = x^2 + y^2 - 1.
        \end{aligned}
    \]
    In the language of the Lagrange multiplier method, we are finding the extrema of \(f\) subject to the constraints \(g_1=0\) and \(g_2 = 0\).
    Applying the method leads us to the a system of 5 equations and 5 unknowns,
    \[
        \nabla f  = \lambda_1 \nabla g_1  + \lambda_2 \nabla g_2,
        \quad
        g_1 = 0,
        \quad
        g_2 = 0.
    \]
    We proceed to solve this system of equations in order to obtain a set of points which are the points where the extrema occur.
    We calculate that the gradients are
    \begin{gather*}
        \nabla f (x,y,z) = \begin{pmatrix}
            2 x \\ 2y \\ 2z
        \end{pmatrix},
        \quad
        \nabla g_1(x,y,z) = \begin{pmatrix}
            2x-y \\ 2y - x \\ -2z
        \end{pmatrix},\\
        \nabla g_2(x,y,z) = \begin{pmatrix}
            2x \\ 2y \\ 0
        \end{pmatrix}.
    \end{gather*}
    Consequently the 5 equations are
    \[
        \begin{aligned}
            2x & = \lambda_1 ( 2x -y ) + \lambda_2(2x) \\
            2y & = \lambda_1 ( 2y - x) + \lambda_2(2y) \\
            2z & = \lambda_1(-2z),
        \end{aligned}
    \]
    \[
        x^2 + y^2 = 1,
        \quad
        x^2 - xy + y^2 - z^2 =1.
    \]
    If we combine the 4\textsuperscript{th} and 5\textsuperscript{th} equations we obtain that
    \begin{equation}
        \label{eq:LagrangeA}
        xy + z^2 = 0.
    \end{equation}
    Consequently
    \begin{equation}
        \label{eq:LagrangeB}
        xy \leq 0.
    \end{equation}
    If we multiply the 1\textsuperscript{st} by \(y\), multiply the 2\textsuperscript{nd} by \(x\) and combine we obtain that \(\lambda_1(2x-y)y = \lambda_1(2y - x)x\).
    This means that
    \begin{equation}
        \label{eq:LagrangeC}
        x^2 = y^2
        \quad \text{or} \quad
        \lambda_1 = 0.
    \end{equation}
    For a moment we assume the first case and combined this with the 4\textsuperscript{th} equation.
    This means that \(x^2 +x^2 = 1\) and so \(x = \pm \frac{1}{\sqrt{2}}\).
    In general \(x^2 = y^2\) allows that \(y = \pm x\) but~\eqref{eq:LagrangeB} means that \(y = -x\). Using~\eqref{eq:LagrangeA} to calculate \(z\) we obtain 4 solutions,
    \[
        (\tfrac{-1}{\sqrt{2}},\tfrac{1}{\sqrt{2}},\tfrac{-1}{\sqrt{2}}),
        (\tfrac{-1}{\sqrt{2}},\tfrac{1}{\sqrt{2}},\tfrac{1}{\sqrt{2}}),
        (\tfrac{1}{\sqrt{2}},\tfrac{-1}{\sqrt{2}},\tfrac{-1}{\sqrt{2}}),
        (\tfrac{1}{\sqrt{2}},\tfrac{-1}{\sqrt{2}},\tfrac{1}{\sqrt{2}}).
    \]
    We check that these really are solutions by substituting into the 5 equations.
    Now we need to consider the other case~\eqref{eq:LagrangeC} which we previously ignored.
    Consider the 3\textsuperscript{rd} equation we find that \(z = 0\).
    Consequently, by~\eqref{eq:LagrangeA}, either \(x=0\) or \(y=0\).
    This then means that, by the 4\textsuperscript{th} equation that \(y^2=1\) or \(x^2=1\) respectively.
    Consequently we have obtained another 4 solutions,
    \[
        (-1,0,0),
        (1,0,0),
        (0,-1,0),
        (0,1,0).
    \]
    Again we check that these really are solutions by substituting into the 5 equations.

    Calculating the distance of the points to the origin we find that the first set are equally the closest to the origin and the second set are equally the furthest.
\end{solution}



\begin{task}
    Investigate the stationary points of the scalar field,
    \[
        f(x,y,z) =  e^{-{(x-1)}^2}(y^4 - 8yz + 2z^2).
    \]
\end{task}

\begin{solution}
    First, we compute the gradient,
    \[
        \nabla f(x,y,z) =  \left(
        \begin{array}{c}
                -2(x-1)e^{-{(x-1)}^2}(y^4 - 8yz + 2z^2) \\
                e^{-{(x-1)}^2}(4y^{3} - 8 z)            \\
                e^{-{(x-1)}^2}(-8 y + 4 z)              \\
            \end{array}
        \right).
    \]
    Consequently we know that the statement \(\nabla f(x,y,z) = \mathbf{0}\) is equivalent to the system of equations
    \begin{gather}
        (x-1)(y^4 - 8yz + 2z^2) = 0, \label{eq:stationaryA}\\
        y^3 = 2z,  \label{eq:stationaryB}\\
        z = 2y.    \label{eq:stationaryC}
    \end{gather}
    We proceed to find all the solutions to this system of equations and in doing so we will have found all the stationary points of \(f\).
    Combining~\eqref{eq:stationaryB} and~\eqref{eq:stationaryC} we obtain that \(y^3 = 4y\) and so
    \begin{equation}
        \label{eq:stationaryD}
        y = 0 \quad \text{or} \quad y^2 = 4.
    \end{equation}
    We will use this information later.
    From~\eqref{eq:stationaryA} we know that
    \[
        y^4 - 8yz + 2z^2 = 0
        \quad \text{or} \quad
        x = 1.
    \]
    We proceed considering this case by case.
    In the first case, using also~\eqref{eq:stationaryC}, we obtain that \(y^4 - 16 y^2 + 8y^2 = 0\).
    This means that \(y=0\) or \(y^2 = 8\).
    However the second option is in contradiction with~\eqref{eq:stationaryD} and so \(y=0\) is the only solution.
    Using also~\eqref{eq:stationaryC} we are left with the set of points
    \[
        (a,0,0) \quad \text{for any \(a\in\bR\)}.
    \]
    We check that this really does satisfy the system of equations without further restrictions on the \(x\)-coordinate.
    Consequently each of these points is a stationary point.
    It now remains to consider the case which previously we ignored, namely \(x=1\).
    Using also~\eqref{eq:stationaryD} and~\eqref{eq:stationaryC} we obtain the points
    \[
        (1,-2,-4)
        \quad \text{and} \quad
        (1,2,4)
    \]
    (the point \((1,0,0)\) is already included in the previous set).
    Again we check that these two points satisfy the system of equations and are therefore both stationary points.

    In order to classify the stationary points we calculate the Hessian matrix.
    For convenience we use the notation
    \[
        \mathbf{H}f =
        \begin{pmatrix}
            h_{11} & h_{12} & h_{13} \\
            h_{21} & h_{22} & h_{23} \\
            h_{31} & h_{32} & h_{33}
        \end{pmatrix}.
    \]
    We calculate (since the matrix is symmetric we only need at most 6 of the terms)
    \[
        \begin{aligned}
            h_{11}(x,y,z)
             & = e^{-{(x-1)}^2} (y^4 - 8yz + 2z^2) (-2 + 4{(x-1)}^2), \\
            h_{12}(x,y,z)
             & = -2(x-1) e^{-{(x-1)}^2} (4y^3 - 8z),                  \\
            h_{13}(x,y,z)
             & = -2(x-1) e^{-{(x-1)}^2} (-8y+4z),                     \\
            h_{22}(x,y,z)
             & = e^{-{(x-1)}^2}(12y^2),                               \\
            h_{23}(x,y,z)
             & = e^{-{(x-1)}^2}(-8),                                  \\
            h_{33}(x,y,z)
             & = e^{-{(x-1)}^2} (4).                                  \\
        \end{aligned}
    \]
    Evaluating the Hessian at two of the stationary points we obtain that (that \(x=1\) means that several terms disappear and the others are easy to calculate),
    \[
        \begin{aligned}
            \mathbf{H}f(1,0,0) & =
            \begin{pmatrix}
                0 & 0  & 0  \\
                0 & 0  & -8 \\
                0 & -8 & 4
            \end{pmatrix}, \\
            \mathbf{H}f(1,2,4) & =
            \begin{pmatrix}
                32 & 0  & 0  \\
                0  & 48 & -8 \\
                0  & -8 & 4
            \end{pmatrix}.
        \end{aligned}
    \]
    The first matrix has one positive and one negative eigenvalue so \((1,0,0)\) is a saddle point.
    On the other hand, the eigenvalues of the second matrix are all positive and so the function \(f(x,y,z)\) takes a minimum at the point \((1,2,4)\).
\end{solution}


\section{Curves \& line integrals}

\begin{task}
    Determine if the following two vector fields are conservative on \(\mathbb{R}^2\).
    \[
        \begin{aligned}
            \mathbf{f}(x,y)
             & =
            \begin{pmatrix}
                2y(1 + x )e^x \\ 2x e^x
            \end{pmatrix}, \\
            \mathbf{g}(x,y)
             & =
            \begin{pmatrix}
                2y^2 \\
                x+2
            \end{pmatrix}.
        \end{aligned}
    \]
    For \((x,y) \neq (0,0)\) let
    \[
        \mathbf{h}(x,y) =
        \begin{pmatrix}
            3 y {(x^2+y^2)}^{-1} \\
            3 x {(x^2+y^2)}^{-1}
        \end{pmatrix}.
    \]
    Is the vector field \(\mathbf{h}\) conservative on the domain \(\{(x,y): |y| > 0 \}\)?
    Is the vector field \(\mathbf{h}\) conservative on the domain \(\{(x,y): 1 \leq x^2+y^2 \leq 4 \}\)?

    Let \(\boldsymbol\alpha\) denote the anticlockwise triangular path with three straight segments and vertices \((0,0)\), \((1,0)\), \((0,1)\).
    With \(\mathbf{g}\) the vector-field defined above, calculate the line integral
    \(\int \mathbf{g} \ d\boldsymbol\alpha\).
\end{task}

\begin{solution}
    We see that \(\mathbf{f}(x,y)\) is conservative because, if \(\varphi (x,y) = 2xy e^x \) then
    \[
        \nabla \varphi (x,y) = \begin{pmatrix}
            2y(1 + x )e^x \\ 2 x e^x
        \end{pmatrix}.
    \]
    Comparing the \(y\) derivative of the first component and the \(x\) derivative of the second component we see that the other two vector fields are not conservative on any domain.

    Let's calculate the line integral.
    It is convenient to divide the path \(\boldsymbol{\alpha}\) into three pieces:
    \begin{itemize}
        \item   \(\boldsymbol{\alpha}_1(t) = (t,0)\), \(t\in[0,1]\),
        \item   \(\boldsymbol{\alpha}_2(t) = (1-t,t)\), \(t\in[0,1]\),
        \item   \(\boldsymbol{\alpha}_3(t) = (0,1-t)\), \(t\in[0,1]\).
    \end{itemize}
    This in means that
    \(\boldsymbol{\alpha}_1'(t) = \left(\begin{smallmatrix}  1 \\ 0  \end{smallmatrix}\right)\),
    \(\boldsymbol{\alpha}_2'(t) =  \left(\begin{smallmatrix}  -1 \\ 1  \end{smallmatrix}\right)\),
    \(\boldsymbol{\alpha}_3'(t) =  \left(\begin{smallmatrix}  0 \\ -1  \end{smallmatrix}\right)\).
    Since
    \(\mathbf{g}(x,y) =
    \left(\begin{smallmatrix}
        2 y^2 \\ x + 2
    \end{smallmatrix}\right)\), we calculate that
    \[
        \mathbf{g}(\boldsymbol{\alpha}_1(t)) =
        \left(\begin{smallmatrix}
            0 \\ t + 2
        \end{smallmatrix}\right),
        \quad
        \mathbf{g}(\boldsymbol{\alpha}_2(t)) =
        \left(\begin{smallmatrix}
            2 t^2 \\ 1 - t + 2
        \end{smallmatrix}\right),
        \quad
        \mathbf{g}(\boldsymbol{\alpha}_3(t)) =
        \left(\begin{smallmatrix}
            2 {(1-t)}^2 \\ 2
        \end{smallmatrix}\right).
    \]
    And so
    \[
        \begin{aligned}
            \boldsymbol{\alpha}_1'(t) \cdot \mathbf{g}(\boldsymbol{\alpha}_1(t)) & = 0,               \\
            \boldsymbol{\alpha}_2'(t) \cdot \mathbf{g}(\boldsymbol{\alpha}_2(t)) & = 1 + 2 -t - 2t^2, \\
            \boldsymbol{\alpha}_3'(t) \cdot \mathbf{g}(\boldsymbol{\alpha}_3(t)) & = -2.
        \end{aligned}
    \]
    Finally
    \[
        \begin{aligned}
            \int \mathbf{g} \ d\boldsymbol\alpha
             & = \int_0^1 1  -t - 2t^2 \ dt                           \\
             & = {\left[t - \frac{t^2}{2} - \frac{2 t^3}{3}\right]}_0^1
            = 1 - \frac{1}{2} - \frac{2}{3}
            = \frac{3-4}{6} = - \frac{1}{6}.
        \end{aligned}
    \]
\end{solution}

\section{Multiple integrals}

\section{Surface integrals}